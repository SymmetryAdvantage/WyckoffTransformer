{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T20:13:03.797220Z",
     "iopub.status.busy": "2024-04-09T20:13:03.796615Z",
     "iopub.status.idle": "2024-04-09T20:13:03.805553Z",
     "shell.execute_reply": "2024-04-09T20:13:03.804858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_NOTEBOOK_NAME=Train.ipynb\n",
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n",
      "env: PYTORCH_CUDA_ALLOC_CONF=backend:cudaMallocAsync\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_NOTEBOOK_NAME Train.ipynb\n",
    "%env CUDA_DEVICE_ORDER PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES 1\n",
    "%env PYTORCH_CUDA_ALLOC_CONF backend:cudaMallocAsync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T20:13:03.824667Z",
     "iopub.status.busy": "2024-04-09T20:13:03.823948Z",
     "iopub.status.idle": "2024-04-09T20:13:19.509731Z",
     "shell.execute_reply": "2024-04-09T20:13:19.508404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "from mp_20_utils import load_all_data\n",
    "from tokenization import MASK_SITE\n",
    "device = 'cuda'\n",
    "dataset = 'mp_ternary'\n",
    "datasets_pd, torch_datasets, site_to_ids, element_to_ids, spacegroup_to_ids, max_len = load_all_data(\n",
    "    device=device, allow_retokenize=False, dataset=dataset)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del torch_datasets['test'], datasets_pd['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T20:13:19.517101Z",
     "iopub.status.busy": "2024-04-09T20:13:19.516722Z",
     "iopub.status.idle": "2024-04-09T20:13:19.542824Z",
     "shell.execute_reply": "2024-04-09T20:13:19.542297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from operator import itemgetter\n",
    "max_enumeration = max(map(\n",
    "    lambda dataframe: max(chain.from_iterable(dataframe.symmetry_sites_enumeration_padded)),\n",
    "    datasets_pd.values()))\n",
    "print(max_enumeration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T20:13:19.545775Z",
     "iopub.status.busy": "2024-04-09T20:13:19.545606Z",
     "iopub.status.idle": "2024-04-09T20:13:19.730233Z",
     "shell.execute_reply": "2024-04-09T20:13:19.729739Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
    "torch.set_float32_matmul_precision('high')\n",
    "from wyckoff_transformer import WyckoffTransformerModel, WyckoffTrainer\n",
    "d_hid = 170  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 3  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 1  # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.1  # dropout probability\n",
    "n_space_groups = len(spacegroup_to_ids)\n",
    "# Not all 230 space groups are present in the data\n",
    "model = WyckoffTransformerModel(\n",
    "    n_space_groups = n_space_groups,\n",
    "    n_sites = len(site_to_ids),\n",
    "    n_elements = len(element_to_ids),\n",
    "    max_enumeration = max_enumeration,\n",
    "    d_space_groups = 16,\n",
    "    d_sites = 64,\n",
    "    d_species = 64,\n",
    "    nhead=nhead,\n",
    "    d_hid=d_hid,\n",
    "    max_len=max_len,\n",
    "    nlayers=nlayers,\n",
    "    dropout=dropout).to(device)\n",
    "#model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T20:13:19.732722Z",
     "iopub.status.busy": "2024-04-09T20:13:19.732403Z",
     "iopub.status.idle": "2024-04-09T21:45:28.351535Z",
     "shell.execute_reply": "2024-04-09T21:45:28.350339Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkazeev\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kna/WyckoffTransformer/wandb/run-20240514_153731-1g77tw5u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kazeev/WyckoffTransformer/runs/1g77tw5u' target=\"_blank\">worldly-tree-182</a></strong> to <a href='https://wandb.ai/kazeev/WyckoffTransformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kazeev/WyckoffTransformer' target=\"_blank\">https://wandb.ai/kazeev/WyckoffTransformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kazeev/WyckoffTransformer/runs/1g77tw5u' target=\"_blank\">https://wandb.ai/kazeev/WyckoffTransformer/runs/1g77tw5u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 val_loss_epoch 43.08405303955078 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 50 val_loss_epoch 42.17355728149414 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 60 val_loss_epoch 33.82870864868164 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 90 val_loss_epoch 31.943235397338867 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 120 val_loss_epoch 27.524681091308594 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 150 val_loss_epoch 27.292049407958984 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 170 val_loss_epoch 26.128114700317383 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 190 val_loss_epoch 25.279027938842773 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 250 val_loss_epoch 25.17259407043457 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 270 val_loss_epoch 22.729679107666016 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 380 val_loss_epoch 22.688573837280273 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 410 val_loss_epoch 22.254220962524414 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 430 val_loss_epoch 21.89360809326172 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 440 val_loss_epoch 21.662181854248047 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 450 val_loss_epoch 21.046083450317383 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 500 val_loss_epoch 20.423295974731445 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 550 val_loss_epoch 20.10816192626953 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 590 val_loss_epoch 19.72616195678711 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 600 val_loss_epoch 18.976911544799805 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 640 val_loss_epoch 18.692157745361328 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 700 val_loss_epoch 17.992755889892578 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 830 val_loss_epoch 17.139156341552734 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 890 val_loss_epoch 17.063344955444336 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 930 val_loss_epoch 16.787620544433594 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1000 val_loss_epoch 16.493915557861328 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1010 val_loss_epoch 16.449487686157227 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1060 val_loss_epoch 16.395099639892578 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1090 val_loss_epoch 16.237279891967773 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1100 val_loss_epoch 16.08907127380371 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1130 val_loss_epoch 15.984725952148438 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1140 val_loss_epoch 15.934798240661621 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1180 val_loss_epoch 15.646734237670898 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1260 val_loss_epoch 15.40475082397461 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1290 val_loss_epoch 15.347970008850098 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1360 val_loss_epoch 15.047327995300293 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1400 val_loss_epoch 14.606560707092285 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1470 val_loss_epoch 14.411308288574219 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1540 val_loss_epoch 14.395581245422363 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1550 val_loss_epoch 14.215394973754883 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1680 val_loss_epoch 13.964583396911621 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1760 val_loss_epoch 13.920343399047852 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1770 val_loss_epoch 13.774345397949219 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1800 val_loss_epoch 13.742341995239258 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1820 val_loss_epoch 13.68792724609375 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1940 val_loss_epoch 13.535635948181152 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1950 val_loss_epoch 13.53490924835205 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n",
      "Epoch 1990 val_loss_epoch 13.477145195007324 saved to checkpoints/2024-05-14_15-37-30/best_model_params.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "trainer = WyckoffTrainer(model, torch_datasets, max_len,\n",
    "                         site_mask=torch.tensor(site_to_ids[MASK_SITE]).to(device),\n",
    "                         element_pad=torch.tensor(element_to_ids[\"PAD\"]).to(device),\n",
    "                         site_pad=torch.tensor(site_to_ids[\"PAD\"]).to(device))\n",
    "trainer.train(epochs=10000, val_period=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wyckofftransformer-FeCwefly-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
