{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T20:13:03.797220Z",
     "iopub.status.busy": "2024-04-09T20:13:03.796615Z",
     "iopub.status.idle": "2024-04-09T20:13:03.805553Z",
     "shell.execute_reply": "2024-04-09T20:13:03.804858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_NOTEBOOK_NAME=Train.ipynb\n",
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n",
      "env: PYTORCH_CUDA_ALLOC_CONF=backend:cudaMallocAsync\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_NOTEBOOK_NAME Train.ipynb\n",
    "%env CUDA_DEVICE_ORDER PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES 1\n",
    "%env PYTORCH_CUDA_ALLOC_CONF backend:cudaMallocAsync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T20:13:03.824667Z",
     "iopub.status.busy": "2024-04-09T20:13:03.823948Z",
     "iopub.status.idle": "2024-04-09T20:13:19.509731Z",
     "shell.execute_reply": "2024-04-09T20:13:19.508404Z"
    }
   },
   "outputs": [],
   "source": [
    "from mp_20_utils import load_all_data\n",
    "from tokenization import MASK_SITE\n",
    "device = 'cuda'\n",
    "datasets_pd, torch_datasets, site_to_ids, element_to_ids, spacegroup_to_ids, max_len = load_all_data(\n",
    "    device=device, allow_retokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T20:13:19.517101Z",
     "iopub.status.busy": "2024-04-09T20:13:19.516722Z",
     "iopub.status.idle": "2024-04-09T20:13:19.542824Z",
     "shell.execute_reply": "2024-04-09T20:13:19.542297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from operator import itemgetter\n",
    "max_enumeration = max(map(\n",
    "    lambda dataframe: max(chain.from_iterable(dataframe.symmetry_sites_enumeration_padded)),\n",
    "    datasets_pd.values()))\n",
    "print(max_enumeration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T20:13:19.545775Z",
     "iopub.status.busy": "2024-04-09T20:13:19.545606Z",
     "iopub.status.idle": "2024-04-09T20:13:19.730233Z",
     "shell.execute_reply": "2024-04-09T20:13:19.729739Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
    "torch.set_float32_matmul_precision('high')\n",
    "from wyckoff_transformer import WyckoffTransformerModel, WyckoffTrainer\n",
    "d_hid = 170  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 3  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 1  # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.1  # dropout probability\n",
    "n_space_groups = len(spacegroup_to_ids)\n",
    "# Not all 230 space groups are present in the data\n",
    "model = WyckoffTransformerModel(\n",
    "    n_space_groups = n_space_groups,\n",
    "    n_sites = len(site_to_ids),\n",
    "    n_elements = len(element_to_ids),\n",
    "    max_enumeration = max_enumeration,\n",
    "    d_space_groups = 16,\n",
    "    d_sites = 64,\n",
    "    d_species = 64,\n",
    "    nhead=nhead,\n",
    "    d_hid=d_hid,\n",
    "    max_len=max_len,\n",
    "    nlayers=nlayers,\n",
    "    dropout=dropout).to(device)\n",
    "#model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T20:13:19.732722Z",
     "iopub.status.busy": "2024-04-09T20:13:19.732403Z",
     "iopub.status.idle": "2024-04-09T21:45:28.351535Z",
     "shell.execute_reply": "2024-04-09T21:45:28.350339Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkazeev\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/kna/WyckoffTransformer_dev/wandb/run-20240410_041320-fm6j3hkb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlively-fog-170\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kazeev/WyckoffTransformer\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kazeev/WyckoffTransformer/runs/fm6j3hkb\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 val_loss_epoch 42.09566116333008 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 val_loss_epoch 36.17131042480469 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 val_loss_epoch 33.924076080322266 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 val_loss_epoch 32.68952178955078 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 val_loss_epoch 28.27488136291504 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150 val_loss_epoch 26.31616973876953 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210 val_loss_epoch 25.823863983154297 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220 val_loss_epoch 25.45132064819336 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250 val_loss_epoch 24.34197235107422 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270 val_loss_epoch 24.292036056518555 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310 val_loss_epoch 22.785245895385742 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370 val_loss_epoch 20.865114212036133 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490 val_loss_epoch 20.59937858581543 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 510 val_loss_epoch 20.195005416870117 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 520 val_loss_epoch 19.46631622314453 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550 val_loss_epoch 19.440195083618164 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600 val_loss_epoch 19.02964210510254 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 650 val_loss_epoch 18.606233596801758 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 730 val_loss_epoch 18.538646697998047 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 760 val_loss_epoch 17.77493667602539 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 780 val_loss_epoch 17.52874755859375 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 830 val_loss_epoch 17.12831687927246 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 860 val_loss_epoch 16.92087745666504 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 930 val_loss_epoch 16.6191463470459 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 950 val_loss_epoch 16.438976287841797 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1030 val_loss_epoch 16.343486785888672 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1050 val_loss_epoch 15.548245429992676 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1120 val_loss_epoch 15.05649185180664 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1130 val_loss_epoch 14.961568832397461 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1150 val_loss_epoch 14.908406257629395 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1240 val_loss_epoch 14.731295585632324 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1260 val_loss_epoch 14.71292495727539 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1280 val_loss_epoch 14.706323623657227 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1300 val_loss_epoch 14.576681137084961 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1330 val_loss_epoch 14.340163230895996 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1420 val_loss_epoch 14.170942306518555 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1430 val_loss_epoch 13.998507499694824 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500 val_loss_epoch 13.906363487243652 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1510 val_loss_epoch 13.79093074798584 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1520 val_loss_epoch 13.566489219665527 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1560 val_loss_epoch 13.483532905578613 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1630 val_loss_epoch 13.2960786819458 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1720 val_loss_epoch 13.166468620300293 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1730 val_loss_epoch 13.152034759521484 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1790 val_loss_epoch 13.014738082885742 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1840 val_loss_epoch 12.926884651184082 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1860 val_loss_epoch 12.859967231750488 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1870 val_loss_epoch 12.784997940063477 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1880 val_loss_epoch 12.75613021850586 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1960 val_loss_epoch 12.609885215759277 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2080 val_loss_epoch 12.445854187011719 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2130 val_loss_epoch 12.44139289855957 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2140 val_loss_epoch 12.433706283569336 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2150 val_loss_epoch 12.427144050598145 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2180 val_loss_epoch 12.276086807250977 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2200 val_loss_epoch 12.222341537475586 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2280 val_loss_epoch 12.118439674377441 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2320 val_loss_epoch 12.104253768920898 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2330 val_loss_epoch 12.096482276916504 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2350 val_loss_epoch 12.045236587524414 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2430 val_loss_epoch 12.002734184265137 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2440 val_loss_epoch 11.99535083770752 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2450 val_loss_epoch 11.956657409667969 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2520 val_loss_epoch 11.921292304992676 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2560 val_loss_epoch 11.91292667388916 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2570 val_loss_epoch 11.896989822387695 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2590 val_loss_epoch 11.736482620239258 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2680 val_loss_epoch 11.694787979125977 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2740 val_loss_epoch 11.673587799072266 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2780 val_loss_epoch 11.555537223815918 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2910 val_loss_epoch 11.503901481628418 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2930 val_loss_epoch 11.440361022949219 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2940 val_loss_epoch 11.430061340332031 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3000 val_loss_epoch 11.34819221496582 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3130 val_loss_epoch 11.286752700805664 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3200 val_loss_epoch 11.26839828491211 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3210 val_loss_epoch 11.220687866210938 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3220 val_loss_epoch 11.130090713500977 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3440 val_loss_epoch 11.092948913574219 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3500 val_loss_epoch 11.085564613342285 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3510 val_loss_epoch 11.04147720336914 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3530 val_loss_epoch 11.040570259094238 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3550 val_loss_epoch 11.03213882446289 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3680 val_loss_epoch 11.03164005279541 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3740 val_loss_epoch 11.030585289001465 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3750 val_loss_epoch 11.018556594848633 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3840 val_loss_epoch 10.999188423156738 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3850 val_loss_epoch 10.990287780761719 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3860 val_loss_epoch 10.963772773742676 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3880 val_loss_epoch 10.948457717895508 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3890 val_loss_epoch 10.932759284973145 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3950 val_loss_epoch 10.900875091552734 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3960 val_loss_epoch 10.883697509765625 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4140 val_loss_epoch 10.854913711547852 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4160 val_loss_epoch 10.845584869384766 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4300 val_loss_epoch 10.837220191955566 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4310 val_loss_epoch 10.824127197265625 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4360 val_loss_epoch 10.816938400268555 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4530 val_loss_epoch 10.796943664550781 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4550 val_loss_epoch 10.793259620666504 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4990 val_loss_epoch 10.791973114013672 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5000 val_loss_epoch 10.778328895568848 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5010 val_loss_epoch 10.770669937133789 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5030 val_loss_epoch 10.767024993896484 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5280 val_loss_epoch 10.755324363708496 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5490 val_loss_epoch 10.74834156036377 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5500 val_loss_epoch 10.745928764343262 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5650 val_loss_epoch 10.74542236328125 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5780 val_loss_epoch 10.737957954406738 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5800 val_loss_epoch 10.734309196472168 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5930 val_loss_epoch 10.732871055603027 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5940 val_loss_epoch 10.729436874389648 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5980 val_loss_epoch 10.729192733764648 saved to checkpoints/2024-04-10_04-13-19/best_model_params.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 1.736 MB of 1.736 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 1.736 MB of 1.736 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 1.752 MB of 1.752 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          known_seq_len ‚ñà‚ñÇ‚ñÜ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñà‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÑ‚ñá‚ñÑ‚ñá‚ñÇ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     lr ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_loss_batch ‚ñÅ‚ñÖ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss_element ‚ñÅ‚ñÖ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss_enumeration ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train_loss_site ‚ñÅ‚ñÜ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_loss_epoch ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          known_seq_len 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     lr 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_loss_batch 2116.37988\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss_element 1618.10791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss_enumeration 199.36154\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train_loss_site 298.91043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_loss_epoch 10.73508\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mlively-fog-170\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/kazeev/WyckoffTransformer/runs/fm6j3hkb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/kazeev/WyckoffTransformer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240410_041320-fm6j3hkb/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "trainer = WyckoffTrainer(model, torch_datasets, max_len,\n",
    "                         site_mask=torch.tensor(site_to_ids[MASK_SITE]).to(device),\n",
    "                         element_pad=torch.tensor(element_to_ids[\"PAD\"]).to(device),\n",
    "                         site_pad=torch.tensor(site_to_ids[\"PAD\"]).to(device))\n",
    "trainer.train(epochs=10000, val_period=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wyckofftransformer-FeCwefly-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
