{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T07:04:13.262611Z",
     "iopub.status.busy": "2024-05-17T07:04:13.262052Z",
     "iopub.status.idle": "2024-05-17T07:04:13.268131Z",
     "shell.execute_reply": "2024-05-17T07:04:13.267520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_NOTEBOOK_NAME=Train.ipynb\n",
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n",
      "env: PYTORCH_CUDA_ALLOC_CONF=backend:cudaMallocAsync\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_NOTEBOOK_NAME Train.ipynb\n",
    "%env CUDA_DEVICE_ORDER PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES 1\n",
    "%env PYTORCH_CUDA_ALLOC_CONF backend:cudaMallocAsync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T07:04:13.289897Z",
     "iopub.status.busy": "2024-05-17T07:04:13.289731Z",
     "iopub.status.idle": "2024-05-17T07:04:27.169127Z",
     "shell.execute_reply": "2024-05-17T07:04:27.168535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "from mp_20_utils import load_all_data\n",
    "from tokenization import MASK_SITE\n",
    "device = 'cuda'\n",
    "dataset = 'mp_20_biternary'\n",
    "datasets_pd, torch_datasets, site_to_ids, element_to_ids, spacegroup_to_ids, max_len = load_all_data(\n",
    "    device=device, dataset=dataset)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T07:04:27.174456Z",
     "iopub.status.busy": "2024-05-17T07:04:27.174172Z",
     "iopub.status.idle": "2024-05-17T07:04:27.219980Z",
     "shell.execute_reply": "2024-05-17T07:04:27.219378Z"
    }
   },
   "outputs": [],
   "source": [
    "del torch_datasets['test'], datasets_pd['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T07:04:27.224306Z",
     "iopub.status.busy": "2024-05-17T07:04:27.224133Z",
     "iopub.status.idle": "2024-05-17T07:04:27.239627Z",
     "shell.execute_reply": "2024-05-17T07:04:27.238961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from operator import itemgetter\n",
    "max_enumeration = max(map(\n",
    "    lambda dataframe: max(chain.from_iterable(dataframe.symmetry_sites_enumeration_padded)),\n",
    "    datasets_pd.values()))\n",
    "print(max_enumeration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T07:04:27.242961Z",
     "iopub.status.busy": "2024-05-17T07:04:27.242807Z",
     "iopub.status.idle": "2024-05-17T07:04:27.422049Z",
     "shell.execute_reply": "2024-05-17T07:04:27.421458Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
    "torch.set_float32_matmul_precision('high')\n",
    "from wyckoff_transformer import WyckoffTransformerModel, WyckoffTrainer\n",
    "d_hid = 170  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 3  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 1  # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.1  # dropout probability\n",
    "n_space_groups = len(spacegroup_to_ids)\n",
    "# Not all 230 space groups are present in the data\n",
    "model = WyckoffTransformerModel(\n",
    "    n_space_groups = n_space_groups,\n",
    "    n_sites = len(site_to_ids),\n",
    "    n_elements = len(element_to_ids),\n",
    "    max_enumeration = max_enumeration,\n",
    "    d_space_groups = 16,\n",
    "    d_sites = 64,\n",
    "    d_species = 64,\n",
    "    nhead=nhead,\n",
    "    d_hid=d_hid,\n",
    "    max_len=max_len,\n",
    "    nlayers=nlayers,\n",
    "    dropout=dropout).to(device)\n",
    "#model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T07:04:27.424387Z",
     "iopub.status.busy": "2024-05-17T07:04:27.424129Z",
     "iopub.status.idle": "2024-05-17T08:15:45.236163Z",
     "shell.execute_reply": "2024-05-17T08:15:45.234576Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkazeev\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/kna/WyckoffTransformer/wandb/run-20240517_150429-9pl53nyu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfearless-wind-185\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kazeev/WyckoffTransformer\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kazeev/WyckoffTransformer/runs/9pl53nyu\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 val_loss_epoch 49.168174743652344 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 val_loss_epoch 31.89204216003418 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 val_loss_epoch 29.316516876220703 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 val_loss_epoch 28.844924926757812 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 val_loss_epoch 26.29534149169922 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 val_loss_epoch 24.55354118347168 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160 val_loss_epoch 21.991931915283203 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180 val_loss_epoch 21.840316772460938 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190 val_loss_epoch 20.027328491210938 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240 val_loss_epoch 19.22933006286621 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330 val_loss_epoch 18.121177673339844 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350 val_loss_epoch 18.04521369934082 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360 val_loss_epoch 17.75718879699707 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410 val_loss_epoch 17.724929809570312 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430 val_loss_epoch 17.638751983642578 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440 val_loss_epoch 17.59375 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460 val_loss_epoch 16.881511688232422 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 520 val_loss_epoch 16.26300621032715 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 570 val_loss_epoch 15.959858894348145 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 660 val_loss_epoch 15.577186584472656 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 670 val_loss_epoch 15.523780822753906 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740 val_loss_epoch 15.314111709594727 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800 val_loss_epoch 14.626473426818848 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 830 val_loss_epoch 14.476743698120117 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 850 val_loss_epoch 14.044857025146484 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 980 val_loss_epoch 13.553260803222656 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1020 val_loss_epoch 13.457263946533203 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1110 val_loss_epoch 13.352899551391602 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1150 val_loss_epoch 13.313639640808105 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1170 val_loss_epoch 13.200912475585938 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1180 val_loss_epoch 13.179096221923828 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1190 val_loss_epoch 13.145585060119629 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1220 val_loss_epoch 12.92638111114502 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1270 val_loss_epoch 12.581920623779297 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1360 val_loss_epoch 12.462818145751953 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1430 val_loss_epoch 12.303504943847656 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1460 val_loss_epoch 12.218772888183594 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1490 val_loss_epoch 11.895918846130371 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1610 val_loss_epoch 11.832436561584473 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1620 val_loss_epoch 11.812016487121582 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1750 val_loss_epoch 11.72412109375 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1760 val_loss_epoch 11.591424942016602 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1850 val_loss_epoch 11.561565399169922 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1880 val_loss_epoch 11.438281059265137 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1900 val_loss_epoch 11.318603515625 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1910 val_loss_epoch 11.203008651733398 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2020 val_loss_epoch 11.142242431640625 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2040 val_loss_epoch 11.093249320983887 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2070 val_loss_epoch 11.078269958496094 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2080 val_loss_epoch 11.0365629196167 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2170 val_loss_epoch 10.921740531921387 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2240 val_loss_epoch 10.776374816894531 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2270 val_loss_epoch 10.7477388381958 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2310 val_loss_epoch 10.737421989440918 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2400 val_loss_epoch 10.684467315673828 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2420 val_loss_epoch 10.552791595458984 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2440 val_loss_epoch 10.528768539428711 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2670 val_loss_epoch 10.469534873962402 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2690 val_loss_epoch 10.465910911560059 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2710 val_loss_epoch 10.428768157958984 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2730 val_loss_epoch 10.418219566345215 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2790 val_loss_epoch 10.335209846496582 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2820 val_loss_epoch 10.322430610656738 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2840 val_loss_epoch 10.275920867919922 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2880 val_loss_epoch 10.21777629852295 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3080 val_loss_epoch 10.21536922454834 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3150 val_loss_epoch 10.148788452148438 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3180 val_loss_epoch 10.045968055725098 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3260 val_loss_epoch 10.043882369995117 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3280 val_loss_epoch 10.033453941345215 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3300 val_loss_epoch 10.01419734954834 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3310 val_loss_epoch 10.009891510009766 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3320 val_loss_epoch 9.985862731933594 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3430 val_loss_epoch 9.97821044921875 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3440 val_loss_epoch 9.968724250793457 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3460 val_loss_epoch 9.965307235717773 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3530 val_loss_epoch 9.947561264038086 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3610 val_loss_epoch 9.945072174072266 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3620 val_loss_epoch 9.908747673034668 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3630 val_loss_epoch 9.897550582885742 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3660 val_loss_epoch 9.8563871383667 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4010 val_loss_epoch 9.854269981384277 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4580 val_loss_epoch 9.849032402038574 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4610 val_loss_epoch 9.836894035339355 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4650 val_loss_epoch 9.834268569946289 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4660 val_loss_epoch 9.821868896484375 saved to checkpoints/2024-05-17_15-04-28/best_model_params.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 1.725 MB of 1.738 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.006 MB of 1.738 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.676 MB of 1.738 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 1.723 MB of 1.738 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 1.723 MB of 1.738 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 1.738 MB of 1.738 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          known_seq_len ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñà‚ñà‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñá‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñà‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñÉ‚ñÑ‚ñà‚ñÉ‚ñá‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     lr ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_loss_batch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss_element ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss_enumeration ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train_loss_site ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_loss_epoch ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          known_seq_len 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     lr 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_loss_batch 66.53387\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss_element 66.53387\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss_enumeration 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train_loss_site 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_loss_epoch 9.87184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mfearless-wind-185\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/kazeev/WyckoffTransformer/runs/9pl53nyu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/kazeev/WyckoffTransformer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240517_150429-9pl53nyu/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "trainer = WyckoffTrainer(model, torch_datasets, max_len,\n",
    "                         site_mask=torch.tensor(site_to_ids[MASK_SITE]).to(device),\n",
    "                         element_pad=torch.tensor(element_to_ids[\"PAD\"]).to(device),\n",
    "                         site_pad=torch.tensor(site_to_ids[\"PAD\"]).to(device))\n",
    "trainer.train(epochs=10000, val_period=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wyckofftransformer-FeCwefly-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
