{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T14:21:45.367491Z",
     "iopub.status.busy": "2024-03-04T14:21:45.367064Z",
     "iopub.status.idle": "2024-03-04T14:21:45.378284Z",
     "shell.execute_reply": "2024-03-04T14:21:45.377165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_NOTEBOOK_NAME=Train.ipynb\n",
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_NOTEBOOK_NAME Train.ipynb\n",
    "%env CUDA_DEVICE_ORDER PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T14:21:45.402464Z",
     "iopub.status.busy": "2024-03-04T14:21:45.401972Z",
     "iopub.status.idle": "2024-03-04T14:21:57.285626Z",
     "shell.execute_reply": "2024-03-04T14:21:57.284968Z"
    }
   },
   "outputs": [],
   "source": [
    "from mp_20_utils import load_all_data\n",
    "from tokenization import MASK_SITE\n",
    "device = 'cuda'\n",
    "datasets_pd, torch_datasets, site_to_ids, element_to_ids, spacegroup_to_ids, max_len = load_all_data(\n",
    "    device=device, allow_retokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T14:21:57.291410Z",
     "iopub.status.busy": "2024-03-04T14:21:57.291235Z",
     "iopub.status.idle": "2024-03-04T14:21:57.488931Z",
     "shell.execute_reply": "2024-03-04T14:21:57.488322Z"
    }
   },
   "outputs": [],
   "source": [
    "from wyckoff_transformer import WyckoffTransformerModel, WyckoffTrainer\n",
    "d_hid = 200  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 4  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 4  # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.2  # dropout probability\n",
    "n_space_groups = len(spacegroup_to_ids)\n",
    "# Not all 230 space groups are present in the data\n",
    "model = WyckoffTransformerModel(\n",
    "    n_space_groups = n_space_groups,\n",
    "    n_sites = len(site_to_ids),\n",
    "    n_elements = len(element_to_ids),\n",
    "    d_space_groups = 16,\n",
    "    d_sites = 64,\n",
    "    d_species = 64,\n",
    "    nhead=nhead,\n",
    "    d_hid=d_hid,\n",
    "    nlayers=nlayers,\n",
    "    dropout=dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T14:21:57.491365Z",
     "iopub.status.busy": "2024-03-04T14:21:57.491103Z",
     "iopub.status.idle": "2024-03-04T15:04:35.536787Z",
     "shell.execute_reply": "2024-03-04T15:04:35.535576Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkazeev\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kna/WyckoffTransformer/wandb/run-20240409_160000-nbwey9po</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kazeev/WyckoffTransformer/runs/nbwey9po/workspace' target=\"_blank\">spring-dawn-100</a></strong> to <a href='https://wandb.ai/kazeev/WyckoffTransformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kazeev/WyckoffTransformer' target=\"_blank\">https://wandb.ai/kazeev/WyckoffTransformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kazeev/WyckoffTransformer/runs/nbwey9po/workspace' target=\"_blank\">https://wandb.ai/kazeev/WyckoffTransformer/runs/nbwey9po/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best val_loss_epoch 3.80627179145813, saving the model\n",
      "Epoch 10 val_loss_epoch 3.80627179145813 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 2.7428152561187744, saving the model\n",
      "Epoch 20 val_loss_epoch 2.7428152561187744 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 2.3932714462280273, saving the model\n",
      "Epoch 40 val_loss_epoch 2.3932714462280273 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.8791073560714722, saving the model\n",
      "Epoch 50 val_loss_epoch 1.8791073560714722 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.795858383178711, saving the model\n",
      "Epoch 60 val_loss_epoch 1.795858383178711 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.705923080444336, saving the model\n",
      "Epoch 90 val_loss_epoch 1.705923080444336 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.6771881580352783, saving the model\n",
      "Epoch 130 val_loss_epoch 1.6771881580352783 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.5915950536727905, saving the model\n",
      "Epoch 170 val_loss_epoch 1.5915950536727905 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.5663464069366455, saving the model\n",
      "Epoch 230 val_loss_epoch 1.5663464069366455 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.5531009435653687, saving the model\n",
      "Epoch 250 val_loss_epoch 1.5531009435653687 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.4945796728134155, saving the model\n",
      "Epoch 320 val_loss_epoch 1.4945796728134155 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.4902993440628052, saving the model\n",
      "Epoch 340 val_loss_epoch 1.4902993440628052 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.4228967428207397, saving the model\n",
      "Epoch 360 val_loss_epoch 1.4228967428207397 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.4196561574935913, saving the model\n",
      "Epoch 410 val_loss_epoch 1.4196561574935913 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.4075573682785034, saving the model\n",
      "Epoch 420 val_loss_epoch 1.4075573682785034 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.365308165550232, saving the model\n",
      "Epoch 440 val_loss_epoch 1.365308165550232 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.338331699371338, saving the model\n",
      "Epoch 460 val_loss_epoch 1.338331699371338 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.3198376893997192, saving the model\n",
      "Epoch 480 val_loss_epoch 1.3198376893997192 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.2739919424057007, saving the model\n",
      "Epoch 490 val_loss_epoch 1.2739919424057007 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.2124608755111694, saving the model\n",
      "Epoch 510 val_loss_epoch 1.2124608755111694 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.1536945104599, saving the model\n",
      "Epoch 520 val_loss_epoch 1.1536945104599 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.0931103229522705, saving the model\n",
      "Epoch 560 val_loss_epoch 1.0931103229522705 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.0688437223434448, saving the model\n",
      "Epoch 580 val_loss_epoch 1.0688437223434448 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.0480417013168335, saving the model\n",
      "Epoch 600 val_loss_epoch 1.0480417013168335 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 1.0460861921310425, saving the model\n",
      "Epoch 620 val_loss_epoch 1.0460861921310425 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.9645852446556091, saving the model\n",
      "Epoch 630 val_loss_epoch 0.9645852446556091 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.9365983009338379, saving the model\n",
      "Epoch 660 val_loss_epoch 0.9365983009338379 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.9307975769042969, saving the model\n",
      "Epoch 670 val_loss_epoch 0.9307975769042969 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.9109291434288025, saving the model\n",
      "Epoch 700 val_loss_epoch 0.9109291434288025 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.8939689993858337, saving the model\n",
      "Epoch 710 val_loss_epoch 0.8939689993858337 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.8782532811164856, saving the model\n",
      "Epoch 720 val_loss_epoch 0.8782532811164856 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.875575840473175, saving the model\n",
      "Epoch 750 val_loss_epoch 0.875575840473175 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.8420588374137878, saving the model\n",
      "Epoch 770 val_loss_epoch 0.8420588374137878 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.8050352334976196, saving the model\n",
      "Epoch 780 val_loss_epoch 0.8050352334976196 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.7950746417045593, saving the model\n",
      "Epoch 790 val_loss_epoch 0.7950746417045593 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.7926316857337952, saving the model\n",
      "Epoch 810 val_loss_epoch 0.7926316857337952 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.7866268754005432, saving the model\n",
      "Epoch 820 val_loss_epoch 0.7866268754005432 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.7843615412712097, saving the model\n",
      "Epoch 840 val_loss_epoch 0.7843615412712097 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.7546049952507019, saving the model\n",
      "Epoch 850 val_loss_epoch 0.7546049952507019 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.7259033918380737, saving the model\n",
      "Epoch 910 val_loss_epoch 0.7259033918380737 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.7113270163536072, saving the model\n",
      "Epoch 930 val_loss_epoch 0.7113270163536072 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.7101855278015137, saving the model\n",
      "Epoch 940 val_loss_epoch 0.7101855278015137 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.6895378232002258, saving the model\n",
      "Epoch 960 val_loss_epoch 0.6895378232002258 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.671472430229187, saving the model\n",
      "Epoch 1000 val_loss_epoch 0.671472430229187 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.6564223170280457, saving the model\n",
      "Epoch 1060 val_loss_epoch 0.6564223170280457 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.6494767069816589, saving the model\n",
      "Epoch 1120 val_loss_epoch 0.6494767069816589 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.6309496760368347, saving the model\n",
      "Epoch 1130 val_loss_epoch 0.6309496760368347 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.6280582547187805, saving the model\n",
      "Epoch 1140 val_loss_epoch 0.6280582547187805 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.6214817762374878, saving the model\n",
      "Epoch 1230 val_loss_epoch 0.6214817762374878 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.6121153235435486, saving the model\n",
      "Epoch 1250 val_loss_epoch 0.6121153235435486 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.609174907207489, saving the model\n",
      "Epoch 1280 val_loss_epoch 0.609174907207489 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.600067138671875, saving the model\n",
      "Epoch 1290 val_loss_epoch 0.600067138671875 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5998435020446777, saving the model\n",
      "Epoch 1330 val_loss_epoch 0.5998435020446777 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5942530632019043, saving the model\n",
      "Epoch 1350 val_loss_epoch 0.5942530632019043 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5770480632781982, saving the model\n",
      "Epoch 1390 val_loss_epoch 0.5770480632781982 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5749885439872742, saving the model\n",
      "Epoch 1420 val_loss_epoch 0.5749885439872742 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5734930038452148, saving the model\n",
      "Epoch 1430 val_loss_epoch 0.5734930038452148 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5707807540893555, saving the model\n",
      "Epoch 1490 val_loss_epoch 0.5707807540893555 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.560602068901062, saving the model\n",
      "Epoch 1520 val_loss_epoch 0.560602068901062 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5598217844963074, saving the model\n",
      "Epoch 1530 val_loss_epoch 0.5598217844963074 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5546510219573975, saving the model\n",
      "Epoch 1590 val_loss_epoch 0.5546510219573975 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5492620468139648, saving the model\n",
      "Epoch 1610 val_loss_epoch 0.5492620468139648 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5457629561424255, saving the model\n",
      "Epoch 1630 val_loss_epoch 0.5457629561424255 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5450474619865417, saving the model\n",
      "Epoch 1660 val_loss_epoch 0.5450474619865417 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5428873896598816, saving the model\n",
      "Epoch 1670 val_loss_epoch 0.5428873896598816 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5412533283233643, saving the model\n",
      "Epoch 1750 val_loss_epoch 0.5412533283233643 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5353825092315674, saving the model\n",
      "Epoch 1800 val_loss_epoch 0.5353825092315674 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5348316431045532, saving the model\n",
      "Epoch 1810 val_loss_epoch 0.5348316431045532 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5343529582023621, saving the model\n",
      "Epoch 1840 val_loss_epoch 0.5343529582023621 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5339788794517517, saving the model\n",
      "Epoch 1880 val_loss_epoch 0.5339788794517517 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5288039445877075, saving the model\n",
      "Epoch 1930 val_loss_epoch 0.5288039445877075 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5248247385025024, saving the model\n",
      "Epoch 2020 val_loss_epoch 0.5248247385025024 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5240415930747986, saving the model\n",
      "Epoch 2030 val_loss_epoch 0.5240415930747986 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.519856870174408, saving the model\n",
      "Epoch 2040 val_loss_epoch 0.519856870174408 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.517927348613739, saving the model\n",
      "Epoch 2080 val_loss_epoch 0.517927348613739 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5162899494171143, saving the model\n",
      "Epoch 2150 val_loss_epoch 0.5162899494171143 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5152740478515625, saving the model\n",
      "Epoch 2170 val_loss_epoch 0.5152740478515625 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5123841166496277, saving the model\n",
      "Epoch 2190 val_loss_epoch 0.5123841166496277 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5104925632476807, saving the model\n",
      "Epoch 2270 val_loss_epoch 0.5104925632476807 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5099207758903503, saving the model\n",
      "Epoch 2300 val_loss_epoch 0.5099207758903503 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5091158747673035, saving the model\n",
      "Epoch 2320 val_loss_epoch 0.5091158747673035 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5087167620658875, saving the model\n",
      "Epoch 2360 val_loss_epoch 0.5087167620658875 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5062786340713501, saving the model\n",
      "Epoch 2380 val_loss_epoch 0.5062786340713501 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5041472315788269, saving the model\n",
      "Epoch 2390 val_loss_epoch 0.5041472315788269 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5035966038703918, saving the model\n",
      "Epoch 2500 val_loss_epoch 0.5035966038703918 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.5009893178939819, saving the model\n",
      "Epoch 2510 val_loss_epoch 0.5009893178939819 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.4971393644809723, saving the model\n",
      "Epoch 2610 val_loss_epoch 0.4971393644809723 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.49596452713012695, saving the model\n",
      "Epoch 2680 val_loss_epoch 0.49596452713012695 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.49549731612205505, saving the model\n",
      "Epoch 2750 val_loss_epoch 0.49549731612205505 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.49336734414100647, saving the model\n",
      "Epoch 2760 val_loss_epoch 0.49336734414100647 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.4933548867702484, saving the model\n",
      "Epoch 2770 val_loss_epoch 0.4933548867702484 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.49264049530029297, saving the model\n",
      "Epoch 2820 val_loss_epoch 0.49264049530029297 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.49208933115005493, saving the model\n",
      "Epoch 2830 val_loss_epoch 0.49208933115005493 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.49169573187828064, saving the model\n",
      "Epoch 2870 val_loss_epoch 0.49169573187828064 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.4914267063140869, saving the model\n",
      "Epoch 2890 val_loss_epoch 0.4914267063140869 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.49072763323783875, saving the model\n",
      "Epoch 2920 val_loss_epoch 0.49072763323783875 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.49072185158729553, saving the model\n",
      "Epoch 2950 val_loss_epoch 0.49072185158729553 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.49034029245376587, saving the model\n",
      "Epoch 2970 val_loss_epoch 0.49034029245376587 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.4898362159729004, saving the model\n",
      "Epoch 2980 val_loss_epoch 0.4898362159729004 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.48961886763572693, saving the model\n",
      "Epoch 3010 val_loss_epoch 0.48961886763572693 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.48947736620903015, saving the model\n",
      "Epoch 3030 val_loss_epoch 0.48947736620903015 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.48776736855506897, saving the model\n",
      "Epoch 3070 val_loss_epoch 0.48776736855506897 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.4862627685070038, saving the model\n",
      "Epoch 3130 val_loss_epoch 0.4862627685070038 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.48620396852493286, saving the model\n",
      "Epoch 3140 val_loss_epoch 0.48620396852493286 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.48587632179260254, saving the model\n",
      "Epoch 3260 val_loss_epoch 0.48587632179260254 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.48500320315361023, saving the model\n",
      "Epoch 3280 val_loss_epoch 0.48500320315361023 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n",
      "New best val_loss_epoch 0.4843747615814209, saving the model\n",
      "Epoch 3320 val_loss_epoch 0.4843747615814209 saved to checkpoints/2024-04-09_15-59-59/best_model_params.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/kna/WyckoffTransformer/wyckoff_transformer.py\", line 180, in train\n",
      "    self.train_step()\n",
      "  File \"/home/kna/WyckoffTransformer/wyckoff_transformer.py\", line 152, in train_step\n",
      "    wandb.log({\"train_loss_batch\": loss,\n",
      "  File \"/home/kna/.cache/pypoetry/virtualenvs/wyckofftransformer-FeCwefly-py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 420, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/kna/.cache/pypoetry/virtualenvs/wyckofftransformer-FeCwefly-py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 371, in wrapper_fn\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/kna/.cache/pypoetry/virtualenvs/wyckofftransformer-FeCwefly-py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 361, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/kna/.cache/pypoetry/virtualenvs/wyckofftransformer-FeCwefly-py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 1838, in log\n",
      "    self._log(data=data, step=step, commit=commit)\n",
      "  File \"/home/kna/.cache/pypoetry/virtualenvs/wyckofftransformer-FeCwefly-py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 1602, in _log\n",
      "    self._partial_history_callback(data, step, commit)\n",
      "  File \"/home/kna/.cache/pypoetry/virtualenvs/wyckofftransformer-FeCwefly-py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 1474, in _partial_history_callback\n",
      "    self._backend.interface.publish_partial_history(\n",
      "  File \"/home/kna/.cache/pypoetry/virtualenvs/wyckofftransformer-FeCwefly-py3.10/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 584, in publish_partial_history\n",
      "    item.value_json = json_dumps_safer_history(v)\n",
      "  File \"/home/kna/.cache/pypoetry/virtualenvs/wyckofftransformer-FeCwefly-py3.10/lib/python3.10/site-packages/wandb/util.py\", line 842, in json_dumps_safer_history\n",
      "    return dumps(obj, cls=WandBHistoryJSONEncoder, **kwargs)\n",
      "  File \"/usr/lib/python3.10/json/__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "  File \"/usr/lib/python3.10/json/encoder.py\", line 199, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "  File \"/usr/lib/python3.10/json/encoder.py\", line 257, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "  File \"/home/kna/.cache/pypoetry/virtualenvs/wyckofftransformer-FeCwefly-py3.10/lib/python3.10/site-packages/wandb/util.py\", line 803, in default\n",
      "    obj, converted = json_friendly(obj)\n",
      "  File \"/home/kna/.cache/pypoetry/virtualenvs/wyckofftransformer-FeCwefly-py3.10/lib/python3.10/site-packages/wandb/util.py\", line 615, in json_friendly\n",
      "    return obj.item(), True\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7ea7d71ebb43d9bddebac7512a9254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "trainer = WyckoffTrainer(model, torch_datasets, max_len, torch.tensor(site_to_ids[MASK_SITE]).to(device))\n",
    "trainer.train(epochs=4000, val_period=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wyckofftransformer-FeCwefly-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
