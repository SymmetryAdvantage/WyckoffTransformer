{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22d3e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.core import Composition\n",
    "from pymatgen.core.periodic_table import Element\n",
    "allowed_elements = [Element.from_Z(z) for z in frozenset(range(1, 84)).difference([2, 4, 6, 10, 18, 35, 43, 44, 45, 46, 54, 73, 76, 79, 80, 81, 82] +\n",
    "    list(range(58, 72)) +\n",
    "        list(map(lambda x: x.Z, Composition(\"Os, Hg, Pb, Cd, As, Sb, Te, Se, Pd, Tc, Ru, Sr, Sc, Ir, Cs, Rb, Pt, Ge, Hf, W\".replace(\", \", \"\")).elements)))]\n",
    "allowed_elements = frozenset((e for e in allowed_elements if not e.is_transition_metal))\n",
    "required_elements = frozenset((Element(\"Li\"),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2ee53b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kna/.cache/pypoetry/virtualenvs/wyckofftransformer-FeCwefly-py3.12/lib/python3.12/site-packages/matminer/utils/data.py:326: UserWarning: MagpieData(impute_nan=False):\n",
      "In a future release, impute_nan will be set to True by default.\n",
      "                    This means that features that are missing or are NaNs for elements\n",
      "                    from the data source will be replaced by the average of that value\n",
      "                    over the available elements.\n",
      "                    This avoids NaNs after featurization that are often replaced by\n",
      "                    dataset-dependent averages.\n",
      "  warnings.warn(f\"{self.__class__.__name__}(impute_nan=False):\\n\" + IMPUTE_NAN_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from evaluation.generated_dataset import GeneratedDataset, DATA_KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c9bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import pandas as pd\n",
    "from scripts.cache_generated_datasets import compute_fields_and_cache\n",
    "dft_datasets = {}\n",
    "dataset_config = OmegaConf.load(\"../generated/datasets.yaml\")\n",
    "def load_dataset(transformations, config, dataset):\n",
    "    if transformations and transformations[0] == \"FlowMM\":\n",
    "        # Can't use FlowMM\n",
    "        return\n",
    "    if transformations and transformations[-1] == \"DFT\":\n",
    "        key = tuple(transformations)\n",
    "        try:\n",
    "            dft_datasets[key] = GeneratedDataset.from_cache(key, dataset=dataset).data\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Dataset {dataset} with transformations {transformations} not found in cache.\")\n",
    "            dataset_raw = GeneratedDataset.from_transformations(\n",
    "                    transformations=key,\n",
    "                    dataset=dataset)\n",
    "            dft_datasets[key] = compute_fields_and_cache(dataset_raw).data\n",
    "        dft_datasets[key][\"origin\"]=[key] * len(dft_datasets[key])\n",
    "    else:\n",
    "        for next_transformation, next_config in config.items():\n",
    "            if next_transformation not in DATA_KEYS:\n",
    "                load_dataset(transformations + [next_transformation], next_config, dataset)\n",
    "for dataset, config in dataset_config.items():\n",
    "    load_dataset([], config, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0276749a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24418 DFT structures from 16 datasets.\n",
      "Have acceptable composition: 292 entries.\n"
     ]
    }
   ],
   "source": [
    "from evaluation.novelty import NoveltyFilter, filter_by_unique_structure\n",
    "all_dft_data = pd.concat(dft_datasets.values(), ignore_index=True, copy=False)\n",
    "print(f\"Loaded {len(all_dft_data)} DFT structures from {len(dft_datasets)} datasets.\")\n",
    "acceptable_composition = all_dft_data.structure.map(lambda s:\n",
    "    required_elements.issubset(s.composition) and frozenset(s.composition.elements).issubset(allowed_elements))\n",
    "all_dft_data = all_dft_data[acceptable_composition]\n",
    "print(f\"Have acceptable composition: {len(all_dft_data)} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b745476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_datasets = (\"mp_2022\", \"mp_20\", \"mpts_52\")\n",
    "from itertools import chain\n",
    "novelty_reference = pd.concat(chain(*\n",
    "    ((GeneratedDataset.from_cache((\"split\", part), dataset=reference_dataset).data for part in (\"train\", \"val\", \"test\"))\n",
    "    for reference_dataset in reference_datasets)),\n",
    "    axis=0, ignore_index=True, verify_integrity=False, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d20fd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novel wrt ('mp_2022', 'mp_20', 'mpts_52'): 274 entries.\n"
     ]
    }
   ],
   "source": [
    "novelty_filter = NoveltyFilter(novelty_reference)\n",
    "all_dft_data = novelty_filter.get_novel(all_dft_data)\n",
    "print(f\"Novel wrt {reference_datasets}: {len(all_dft_data)} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7adeb2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique structures: 254 entries.\n"
     ]
    }
   ],
   "source": [
    "all_dft_data = filter_by_unique_structure(all_dft_data)\n",
    "print(f\"Unique structures: {len(all_dft_data)} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5af0c1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy above hull < 0.08 eV: 100 entries.\n"
     ]
    }
   ],
   "source": [
    "E_threshold = 0.08\n",
    "all_dft_data = all_dft_data.loc[all_dft_data.e_above_hull_corrected < E_threshold]\n",
    "print(f\"Energy above hull < {E_threshold} eV: {len(all_dft_data)} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d3f6109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported battery candidates to battery_candidates.csv.gz\n"
     ]
    }
   ],
   "source": [
    "from monty.json import MontyEncoder\n",
    "encoder = MontyEncoder()\n",
    "def to_json(obj):\n",
    "    if isinstance(obj, str):\n",
    "        return obj\n",
    "    if isinstance(obj, frozenset):\n",
    "        obj = tuple(obj)\n",
    "    return encoder.encode(obj)\n",
    "export_filter = all_dft_data.filter(\n",
    "                [\"cdvae_crystal\", \"fingerprint\", \"composition\", \"naive_validity\",\n",
    "                 \"spacegroup_number\", \"density\"], axis=1)\n",
    "all_dft_data.drop(export_filter, axis=1).map(to_json).to_csv(\n",
    "    \"battery_candidates.csv.gz\", index=False)\n",
    "print(\"Exported battery candidates to battery_candidates.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12c10ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "origin\n",
       "(MiAD, CHGNet_free, DFT)                                61\n",
       "(WyckoffTransformer, DiffCSP++10k, CHGNet_free, DFT)    20\n",
       "(DiffCSP, 1k-sample, eq-V2_free, DFT)                    8\n",
       "(DiffCSP, 1k-sample, CHGNet_free, DFT)                   4\n",
       "(SymmCD, CHGNet_free, DFT)                               3\n",
       "(DiffCSP, 1k-sample, DFT)                                2\n",
       "(WyckoffTransformer-letters, DiffCSP++, DFT)             1\n",
       "(WyCryst, CrySPR, CHGNet_fix, DFT)                       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dft_data.origin.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wyckofftransformer-FeCwefly-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
