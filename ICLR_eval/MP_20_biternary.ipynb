{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kna/.cache/pypoetry/virtualenvs/wyckofftransformer-FeCwefly-py3.12/lib/python3.12/site-packages/matminer/utils/data.py:326: UserWarning: MagpieData(impute_nan=False):\n",
      "In a future release, impute_nan will be set to True by default.\n",
      "                    This means that features that are missing or are NaNs for elements\n",
      "                    from the data source will be replaced by the average of that value\n",
      "                    over the available elements.\n",
      "                    This avoids NaNs after featurization that are often replaced by\n",
      "                    dataset-dependent averages.\n",
      "  warnings.warn(f\"{self.__class__.__name__}(impute_nan=False):\\n\" + IMPUTE_NAN_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from evaluation.generated_dataset import GeneratedDataset, load_all_from_config\n",
    "from evaluation.novelty import NoveltyFilter, filter_by_unique_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"WyckoffTransformer\": (\"WyckoffTransformer\", \"CrySPR\", \"CHGNet_fix\"),\n",
    "    \"WyCryst\": (\"WyCryst\", \"CrySPR\", \"CHGNet_fix\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = load_all_from_config(\n",
    "    datasets=list(datasets.values()) + [(\"split\", \"train\"), (\"split\", \"val\"), (\"split\", \"test\")],\n",
    "    dataset_name=\"mp_20_biternary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "novelty_reference = pd.concat([\n",
    "    all_datasets[('split', 'train')].data,\n",
    "    all_datasets[('split', 'val')].data], axis=0, verify_integrity=True)\n",
    "novelty_filter = NoveltyFilter(novelty_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation.statistical_evaluator\n",
    "#import importlib\n",
    "#importlib.reload(evaluation.statistical_evaluator)\n",
    "test_unique = filter_by_unique_structure(all_datasets[('split', 'test')].data)\n",
    "test_novel = novelty_filter.get_novel(test_unique)\n",
    "test_evaluator = evaluation.statistical_evaluator.StatisticalEvaluator(test_novel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_sg_preserved(relaxed_sg, transformations: Tuple[str]) -> pd.Series:\n",
    "    source_sg = all_datasets[(transformations[0],)].data.spacegroup_number\n",
    "    return relaxed_sg == source_sg.reindex_like(relaxed_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01075306602944794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8894823769195629"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_20_biternary_train_val = pd.concat([\n",
    "    all_datasets[('split', 'train')].data,\n",
    "    all_datasets[('split', 'val')].data], axis=0, verify_integrity=True)\n",
    "print((mp_20_biternary_train_val.spacegroup_number == 1).mean())\n",
    "mp_20_biternary_train_val.smact_validity.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluator = evaluation.statistical_evaluator.StatisticalEvaluator(all_datasets[('split', 'test')].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w_template_set = frozenset(mp_20_biternary_train_val.apply(\n",
    "    evaluation.novelty.record_to_anonymous_fingerprint, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8d660c7ee44b5c8636cf780a6793a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999 999 1.0\n",
      "994 994 1.0\n"
     ]
    }
   ],
   "source": [
    "table = pd.DataFrame(\n",
    "    index=datasets.keys(), columns=[\n",
    "        \"Novelty (%)\", \"Structural\", \"Compositional\", \n",
    "        \"Recall\", \"Precision\",\n",
    "        r\"$\\rho$\", \"$E$\", \"# Elements\",\n",
    "        \"S.U.N. (%)\",\n",
    "        \"Novel Template (%)\", \"P1 (%)\",\n",
    "        \"Space Group\", \"S.S.U.N. (%)\"])\n",
    "table.index.name = \"Method\"\n",
    "E_hull_threshold = 0.08\n",
    "unique_sample_size = 992\n",
    "for name, transformations in tqdm(datasets.items()):\n",
    "    dataset = all_datasets[transformations]\n",
    "    unique = filter_by_unique_structure(dataset.data)\n",
    "    print(len(unique), len(dataset.data), len(unique) / len(dataset.data))\n",
    "    novel_template = ~unique.apply(evaluation.novelty.record_to_anonymous_fingerprint, axis=1).isin(train_w_template_set)\n",
    "    table.loc[name, \"Novel Template (%)\"] = 100 * novel_template.mean()\n",
    "    if transformations in ((\"split\", \"train\"), (\"split\", \"val\")):\n",
    "        novel = unique\n",
    "    else:\n",
    "        novel = novelty_filter.get_novel(unique)\n",
    "    table.loc[name, \"Novelty (%)\"] = 100 * len(novel) / len(unique)\n",
    "    if \"structural_validity\" in novel.columns:\n",
    "        table.loc[name, \"Structural\"] = 100 * novel.structural_validity.mean()\n",
    "        table.loc[name, \"Compositional\"] = 100 * novel.smact_validity.mean()\n",
    "    if \"cdvae_crystal\" in novel.columns:\n",
    "        cov_metrics = test_evaluator.get_coverage(novel.cdvae_crystal)    \n",
    "        table.loc[name, \"Recall\"] = 100 * cov_metrics[\"cov_recall\"]\n",
    "        table.loc[name, \"Precision\"] = 100 * cov_metrics[\"cov_precision\"]\n",
    "        novel = novel[novel.structural_validity]\n",
    "        table.loc[name, r\"$\\rho$\"] = test_evaluator.get_density_emd(novel)\n",
    "        table.loc[name, \"$E$\"] = test_evaluator.get_cdvae_e_emd(novel)\n",
    "        table.loc[name, \"# Elements\"] = test_evaluator.get_num_elements_emd(novel)\n",
    "    table.loc[name, \"P1 (%)\"] = 100 * (novel.group == 1).mean()\n",
    "    # table.loc[name, \"# DoF\"] = test_evaluator.get_dof_emd(novel)\n",
    "    table.loc[name, \"Space Group\"] = test_evaluator.get_sg_chi2(novel)\n",
    "    #try:\n",
    "    #    table.loc[name, \"SG preserved (%)\"] = 100 * is_sg_preserved(novel.spacegroup_number, transformations).mean()\n",
    "    #except KeyError:\n",
    "    #    pass\n",
    "    #table.loc[name, \"Elements\"] = test_evaluator.get_elements_chi2(novel)\n",
    "    if \"corrected_chgnet_ehull\" in novel.columns:\n",
    "        # S.U.N. is measured with respect to the initial structures\n",
    "        has_ehull = dataset.data.corrected_chgnet_ehull.notna().sum()\n",
    "        is_sun = (novel.corrected_chgnet_ehull <= E_hull_threshold)\n",
    "        table.loc[name, \"S.U.N. (%)\"] = 100 * is_sun.sum() / has_ehull.sum()\n",
    "        table.loc[name, \"S.S.U.N. (%)\"] = 100 * (is_sun & (novel.group != 1)).sum() / has_ehull.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv(\"tables/mp_20_biternary_paper_summary_table.csv\")\n",
    "table.to_pickle(\"tables/mp_20_biternary_paper_summary_table.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_subset=[\"Novelty (%)\", \"Structural\", \"Compositional\", \"Recall\", \"Precision\", \"S.S.U.N. (%)\", \"S.U.N. (%)\", \"Novel Template (%)\"]\n",
    "# -1 to exclude the MP-20 training set\n",
    "def highlight_max_value(s):\n",
    "    if s.name not in max_subset:\n",
    "        return ['' for _ in s]\n",
    "    is_max = s == s.max()\n",
    "    #is_max.iloc[-1] = False\n",
    "    return ['font-weight: bold' if v else '' for v in is_max]\n",
    "\n",
    "min_subset=[r\"$\\rho$\", \"$E$\", \"# Elements\", \"# DoF\", \"Space Group\", \"Elements\", \"P1 (%)\"]\n",
    "def highlight_min_value(s):\n",
    "    if s.name not in min_subset:\n",
    "        return ['' for _ in s]\n",
    "    is_min = s == s.min()\n",
    "    #is_min.iloc[-1] = False\n",
    "    return ['font-weight: bold' if v else '' for v in is_min]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_2a044\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2a044_level0_col0\" class=\"col_heading level0 col0\" >Novelty (%)</th>\n",
       "      <th id=\"T_2a044_level0_col1\" class=\"col_heading level0 col1\" >Structural</th>\n",
       "      <th id=\"T_2a044_level0_col2\" class=\"col_heading level0 col2\" >Compositional</th>\n",
       "      <th id=\"T_2a044_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_2a044_level0_col4\" class=\"col_heading level0 col4\" >Precision</th>\n",
       "      <th id=\"T_2a044_level0_col5\" class=\"col_heading level0 col5\" >$\\rho$</th>\n",
       "      <th id=\"T_2a044_level0_col6\" class=\"col_heading level0 col6\" >$E$</th>\n",
       "      <th id=\"T_2a044_level0_col7\" class=\"col_heading level0 col7\" ># Elements</th>\n",
       "      <th id=\"T_2a044_level0_col8\" class=\"col_heading level0 col8\" >S.U.N. (%)</th>\n",
       "      <th id=\"T_2a044_level0_col9\" class=\"col_heading level0 col9\" >Novel Template (%)</th>\n",
       "      <th id=\"T_2a044_level0_col10\" class=\"col_heading level0 col10\" >P1 (%)</th>\n",
       "      <th id=\"T_2a044_level0_col11\" class=\"col_heading level0 col11\" >Space Group</th>\n",
       "      <th id=\"T_2a044_level0_col12\" class=\"col_heading level0 col12\" >S.S.U.N. (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Method</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "      <th class=\"blank col11\" >&nbsp;</th>\n",
       "      <th class=\"blank col12\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2a044_level0_row0\" class=\"row_heading level0 row0\" >WyckoffTransformer</th>\n",
       "      <td id=\"T_2a044_row0_col0\" class=\"data row0 col0\" >91.19</td>\n",
       "      <td id=\"T_2a044_row0_col1\" class=\"data row0 col1\" >99.89</td>\n",
       "      <td id=\"T_2a044_row0_col2\" class=\"data row0 col2\" >77.28</td>\n",
       "      <td id=\"T_2a044_row0_col3\" class=\"data row0 col3\" >98.90</td>\n",
       "      <td id=\"T_2a044_row0_col4\" class=\"data row0 col4\" >96.75</td>\n",
       "      <td id=\"T_2a044_row0_col5\" class=\"data row0 col5\" >0.83</td>\n",
       "      <td id=\"T_2a044_row0_col6\" class=\"data row0 col6\" >0.064</td>\n",
       "      <td id=\"T_2a044_row0_col7\" class=\"data row0 col7\" >0.084</td>\n",
       "      <td id=\"T_2a044_row0_col8\" class=\"data row0 col8\" >38.4</td>\n",
       "      <td id=\"T_2a044_row0_col9\" class=\"data row0 col9\" >25.63</td>\n",
       "      <td id=\"T_2a044_row0_col10\" class=\"data row0 col10\" >1.43</td>\n",
       "      <td id=\"T_2a044_row0_col11\" class=\"data row0 col11\" >0.224</td>\n",
       "      <td id=\"T_2a044_row0_col12\" class=\"data row0 col12\" >37.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2a044_level0_row1\" class=\"row_heading level0 row1\" >WyCryst</th>\n",
       "      <td id=\"T_2a044_row1_col0\" class=\"data row1 col0\" >52.62</td>\n",
       "      <td id=\"T_2a044_row1_col1\" class=\"data row1 col1\" >99.81</td>\n",
       "      <td id=\"T_2a044_row1_col2\" class=\"data row1 col2\" >75.53</td>\n",
       "      <td id=\"T_2a044_row1_col3\" class=\"data row1 col3\" >98.85</td>\n",
       "      <td id=\"T_2a044_row1_col4\" class=\"data row1 col4\" >89.27</td>\n",
       "      <td id=\"T_2a044_row1_col5\" class=\"data row1 col5\" >1.35</td>\n",
       "      <td id=\"T_2a044_row1_col6\" class=\"data row1 col6\" >0.128</td>\n",
       "      <td id=\"T_2a044_row1_col7\" class=\"data row1 col7\" >0.003</td>\n",
       "      <td id=\"T_2a044_row1_col8\" class=\"data row1 col8\" >36.6</td>\n",
       "      <td id=\"T_2a044_row1_col9\" class=\"data row1 col9\" >18.51</td>\n",
       "      <td id=\"T_2a044_row1_col10\" class=\"data row1 col10\" >4.79</td>\n",
       "      <td id=\"T_2a044_row1_col11\" class=\"data row1 col11\" >0.815</td>\n",
       "      <td id=\"T_2a044_row1_col12\" class=\"data row1 col12\" >35.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x791c1403d190>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prettify(table):\n",
    "    return table.style.format({\n",
    "    \"Novelty (%)\": \"{:.2f}\",\n",
    "    \"Structural\": \"{:.2f}\",\n",
    "    \"Compositional\": \"{:.2f}\",\n",
    "    \"Recall\": \"{:.2f}\",\n",
    "    \"Precision\": \"{:.2f}\",\n",
    "    r\"$\\rho$\": \"{:.2f}\",\n",
    "    \"$E$\": \"{:.3f}\",\n",
    "    \"# Elements\": \"{:.3f}\",\n",
    "    \"# DoF\": \"{:.3f}\",\n",
    "    \"Space Group\": \"{:.3f}\",\n",
    "    \"Elements\": \"{:.3f}\",\n",
    "    \"Novel Template (%)\": \"{:.2f}\",\n",
    "    \"P1 (%)\": \"{:.2f}\",\n",
    "    \"S.U.N. (%)\": \"{:.1f}\",\n",
    "    \"S.S.U.N. (%)\": \"{:.1f}\",\n",
    "})#.apply(highlight_max_value).apply(highlight_min_value)\n",
    "prettify(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prettify(table.iloc[:, :9]).to_latex(\"tables/mp_20_biternary_summary_similarity_raw.tex\", siunitx=True, convert_css=True)\n",
    "prettify(table.iloc[:, 9:]).to_latex(\"tables/mp_20_biternary_summary_symmetry_raw.tex\", siunitx=True, convert_css=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wyckofftransformer-FeCwefly-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
