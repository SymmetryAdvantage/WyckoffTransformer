{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kna/.cache/pypoetry/virtualenvs/wyckofftransformer-FeCwefly-py3.12/lib/python3.12/site-packages/matminer/utils/data.py:326: UserWarning: MagpieData(impute_nan=False):\n",
      "In a future release, impute_nan will be set to True by default.\n",
      "                    This means that features that are missing or are NaNs for elements\n",
      "                    from the data source will be replaced by the average of that value\n",
      "                    over the available elements.\n",
      "                    This avoids NaNs after featurization that are often replaced by\n",
      "                    dataset-dependent averages.\n",
      "  warnings.warn(f\"{self.__class__.__name__}(impute_nan=False):\\n\" + IMPUTE_NAN_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from evaluation.generated_dataset import GeneratedDataset, load_all_from_config\n",
    "from evaluation.novelty import NoveltyFilter, filter_by_unique_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = {\n",
    "    \"WyFormer\": (\"WyckoffTransformer\", \"CrySPR\", \"CHGNet_fix\"),\n",
    "    \"DiffCSP\": (\"DiffCSP\",)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = load_all_from_config(\n",
    "    datasets=list(raw_datasets.values()) + \\\n",
    "        [(\"split\", \"train\"), (\"split\", \"val\"), (\"split\", \"test\")],\n",
    "    dataset_name=\"perov_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "novelty_reference = pd.concat([\n",
    "    all_datasets[('split', 'train')].data,\n",
    "    all_datasets[('split', 'val')].data], axis=0, verify_integrity=True)\n",
    "novelty_filter = NoveltyFilter(novelty_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation.statistical_evaluator\n",
    "test_evaluator = evaluation.statistical_evaluator.StatisticalEvaluator(\n",
    "    all_datasets[('split', 'test')].data, cdvae_eval_model_name=\"perovskite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation.novelty\n",
    "train_w_template_set = frozenset(novelty_reference.apply(evaluation.novelty.record_to_anonymous_fingerprint, axis=1))\n",
    "train_strict_AFLOW_set = frozenset(novelty_reference.apply(evaluation.novelty.record_to_strict_AFLOW_fingerprint, axis=1))\n",
    "train_relaxed_AFLOW_set = frozenset(novelty_reference.apply(evaluation.novelty.record_to_relaxed_AFLOW_fingerprint, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "perov_5 = pd.concat([\n",
    "    all_datasets[('split', 'train')].data,\n",
    "    all_datasets[('split', 'val')].data,\n",
    "    all_datasets[('split', 'test')].data], axis=0, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18928, 18928)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perov_5.fingerprint.nunique(), perov_5.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9867392223161454"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perov_5.smact_validity.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(perov_5.spacegroup_number == 1).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacegroup_number\n",
       "123    5633\n",
       "25     4310\n",
       "99     3632\n",
       "221    3122\n",
       "47     2231\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perov_5.spacegroup_number.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d9f19a70b14ccc9954877d2f35cf4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique: 992 / 1000 = 0.992\n",
      "Unique: 8229 / 10000 = 0.8229\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Novelty (%)</th>\n",
       "      <th>Structural</th>\n",
       "      <th>Compositional</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>$\\rho$</th>\n",
       "      <th>$E$</th>\n",
       "      <th># Elements</th>\n",
       "      <th>Novel Template (%)</th>\n",
       "      <th>Novel AFLOW on P1</th>\n",
       "      <th>Novel AFLOW on !P1</th>\n",
       "      <th>Novel AFLOW (%)</th>\n",
       "      <th>Novel AFLOW relaxed (%)</th>\n",
       "      <th>P1 (%)</th>\n",
       "      <th>Space Group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WyFormer</th>\n",
       "      <td>62.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.548387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.132252</td>\n",
       "      <td>2.786277</td>\n",
       "      <td>0.05786</td>\n",
       "      <td>0.201613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.302419</td>\n",
       "      <td>0.302419</td>\n",
       "      <td>0.302419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffCSP</th>\n",
       "      <td>47.016648</td>\n",
       "      <td>99.974154</td>\n",
       "      <td>98.578444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.067868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076928</td>\n",
       "      <td>0.388869</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.256004</td>\n",
       "      <td>0.571151</td>\n",
       "      <td>0.51039</td>\n",
       "      <td>0.646329</td>\n",
       "      <td>0.027798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Novelty (%) Structural Compositional Recall Precision    $\\rho$  \\\n",
       "Method                                                                     \n",
       "WyFormer        62.5      100.0     98.548387    NaN       NaN  0.132252   \n",
       "DiffCSP    47.016648  99.974154     98.578444    NaN       NaN  0.067868   \n",
       "\n",
       "               $E$ # Elements Novel Template (%) Novel AFLOW on P1  \\\n",
       "Method                                                               \n",
       "WyFormer  2.786277    0.05786           0.201613               NaN   \n",
       "DiffCSP        NaN   0.076928           0.388869             100.0   \n",
       "\n",
       "         Novel AFLOW on !P1 Novel AFLOW (%) Novel AFLOW relaxed (%)    P1 (%)  \\\n",
       "Method                                                                          \n",
       "WyFormer           0.302419        0.302419                0.302419       0.0   \n",
       "DiffCSP            0.256004        0.571151                 0.51039  0.646329   \n",
       "\n",
       "         Space Group  \n",
       "Method                \n",
       "WyFormer    0.109391  \n",
       "DiffCSP     0.027798  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(\n",
    "    index=raw_datasets.keys(), columns=[\n",
    "        \"Novelty (%)\", \"Structural\", \"Compositional\", \n",
    "        \"Recall\", \"Precision\",\n",
    "        r\"$\\rho$\", \"$E$\", \"# Elements\",\n",
    "        \"Novel Template (%)\", \n",
    "        \"Novel AFLOW on P1\",\n",
    "        \"Novel AFLOW on !P1\",\n",
    "        \"Novel AFLOW (%)\",\n",
    "        \"Novel AFLOW relaxed (%)\",\n",
    "        \"P1 (%)\",\n",
    "        \"Space Group\"])\n",
    "table.index.name = \"Method\"\n",
    "E_hull_threshold = 0.08\n",
    "for name, transformations in tqdm(raw_datasets.items()):\n",
    "    dataset = all_datasets[transformations]\n",
    "    unique = filter_by_unique_structure(dataset.data)\n",
    "    print(f\"Unique: {len(unique)} / {len(dataset.data)} = {len(unique) / len(dataset.data)}\")\n",
    "    novel_template = ~unique.apply(evaluation.novelty.record_to_anonymous_fingerprint, axis=1).isin(train_w_template_set)\n",
    "    table.loc[name, \"Novel Template (%)\"] = 100 * novel_template.mean()\n",
    "    novel_aflow_strict = ~unique.apply(evaluation.novelty.record_to_strict_AFLOW_fingerprint, axis=1).isin(train_strict_AFLOW_set)\n",
    "    table.loc[name, \"Novel AFLOW (%)\"] = 100 * novel_aflow_strict.mean()\n",
    "    novel_aflow_relaxed = ~unique.apply(evaluation.novelty.record_to_relaxed_AFLOW_fingerprint, axis=1).isin(train_relaxed_AFLOW_set)\n",
    "    table.loc[name, \"Novel AFLOW relaxed (%)\"] = 100 * novel_aflow_relaxed.mean()\n",
    "    unique_is_P1 = unique.group == 1\n",
    "    table.loc[name, \"Novel AFLOW on P1\"] = 100 * novel_aflow_strict[unique_is_P1].mean()\n",
    "    table.loc[name, \"Novel AFLOW on !P1\"] = 100 * novel_aflow_strict[~unique_is_P1].mean()\n",
    "    if transformations == (\"split\", \"train\"):\n",
    "        novel = unique\n",
    "    else:\n",
    "        novel = novelty_filter.get_novel(unique)\n",
    "    table.loc[name, \"Novelty (%)\"] = 100 * len(novel) / len(unique)\n",
    "    if \"structural_validity\" in novel.columns:\n",
    "        table.loc[name, \"Structural\"] = 100 * novel.structural_validity.mean()\n",
    "        table.loc[name, \"Compositional\"] = 100 * novel.smact_validity.mean()\n",
    "    if \"cdvae_crystal\" in novel.columns:\n",
    "        cov_metrics = test_evaluator.get_coverage(novel.cdvae_crystal)    \n",
    "        table.loc[name, \"Recall\"] = 100 * cov_metrics[\"cov_recall\"]\n",
    "        table.loc[name, \"Precision\"] = 100 * cov_metrics[\"cov_precision\"]\n",
    "        novel = novel[novel.structural_validity]\n",
    "        table.loc[name, r\"$\\rho$\"] = test_evaluator.get_density_emd(novel)\n",
    "        table.loc[name, \"$E$\"] = test_evaluator.get_cdvae_e_emd(novel)\n",
    "        table.loc[name, \"# Elements\"] = test_evaluator.get_num_elements_emd(novel)\n",
    "    table.loc[name, \"P1 (%)\"] = 100 * (novel.group == 1).mean()\n",
    "    table.loc[name, \"Space Group\"] = test_evaluator.get_sg_chi2(novel)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda43e1476ee4d898e7239fd73b4c5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring 4 generated samples without composition fingerprints.\n"
     ]
    }
   ],
   "source": [
    "cdvae_table = pd.DataFrame(index=pd.Index(raw_datasets.keys(), tupleize_cols=False),\n",
    "    columns=[\n",
    "        \"Structural\", \"Compositional\",\n",
    "        \"Recall\", \"Precision\",\n",
    "        r\"$\\rho$\", \"$E$\", \"# Elements\"])\n",
    "sample_size = 900\n",
    "for name, transformations in tqdm(raw_datasets.items()):\n",
    "    dataset = all_datasets[transformations]\n",
    "    if \"structure\" in dataset.data.columns:\n",
    "        cdvae_table.loc[name, \"Compositional\"] = 100*dataset.data.smact_validity.mean()\n",
    "        cdvae_table.loc[name, \"Structural\"] = 100*dataset.data.structural_validity.mean()\n",
    "        valid = dataset.data[dataset.data.naive_validity]\n",
    "        cov_metrics = test_evaluator.get_coverage(valid.cdvae_crystal, sample_size)\n",
    "        cdvae_table.loc[name, \"Recall\"] = 100*cov_metrics[\"cov_recall\"]\n",
    "        cdvae_table.loc[name, \"Precision\"] = 100*cov_metrics[\"cov_precision\"]\n",
    "        cdvae_table.loc[name, r\"$\\rho$\"] = test_evaluator.get_density_emd(valid)\n",
    "        cdvae_table.loc[name, \"$E$\"] = test_evaluator.get_cdvae_e_emd(valid)\n",
    "        cdvae_table.loc[name, \"# Elements\"] = test_evaluator.get_num_elements_emd(valid)\n",
    "cdvae_table.to_csv(\"tables/cdvae_metrics_no_relax_table.csv\")\n",
    "#prettify(cdvae_table).to_latex(\"tables/cdvae_metrics_no_relax_table.tex\", siunitx=True, convert_css=True)\n",
    "#prettify(cdvae_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Structural</th>\n",
       "      <th>Compositional</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>$\\rho$</th>\n",
       "      <th>$E$</th>\n",
       "      <th># Elements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WyFormer</th>\n",
       "      <td>100.0</td>\n",
       "      <td>98.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>79.762219</td>\n",
       "      <td>0.132511</td>\n",
       "      <td>2.83335</td>\n",
       "      <td>0.041792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiffCSP</th>\n",
       "      <td>99.99</td>\n",
       "      <td>98.75</td>\n",
       "      <td>98.555556</td>\n",
       "      <td>84.174373</td>\n",
       "      <td>0.077988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Structural Compositional     Recall  Precision    $\\rho$      $E$  \\\n",
       "WyFormer      100.0          98.2       70.0  79.762219  0.132511  2.83335   \n",
       "DiffCSP       99.99         98.75  98.555556  84.174373  0.077988      NaN   \n",
       "\n",
       "         # Elements  \n",
       "WyFormer   0.041792  \n",
       "DiffCSP    0.035128  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdvae_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wyckofftransformer-FeCwefly-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
